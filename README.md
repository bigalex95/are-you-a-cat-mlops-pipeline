# ğŸ± Are You a Cat? MLOps Pipeline

[![Python](https://img.shields.io/badge/Python-3.10-blue.svg)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.13+-orange.svg)](https://www.tensorflow.org/)
[![MLflow](https://img.shields.io/badge/MLflow-2.8+-0194E2.svg)](https://mlflow.org/)
[![Airflow](https://img.shields.io/badge/Airflow-2.7+-017CEE.svg)](https://airflow.apache.org/)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.28+-FF4B4B.svg)](https://streamlit.io/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> **A complete end-to-end MLOps pipeline demonstrating Level 3 MLOps maturity with automated training, tracking, deployment, monitoring, and feedback loops.**

---

## ğŸ“‹ Table of Contents

- [Overview](#-overview)
- [Architecture](#-architecture)
- [Features](#-features)
- [Technology Stack](#-technology-stack)
- [Project Structure](#-project-structure)
- [Prerequisites](#-prerequisites)
- [Quick Start](#-quick-start)
- [Usage Guide](#-usage-guide)
- [Monitoring & Observability](#-monitoring--observability)
- [MLOps Maturity Level](#-mlops-maturity-level)
- [Learning Objectives](#-learning-objectives)
- [Development Roadmap](#-development-roadmap)
- [Contributing](#-contributing)
- [Troubleshooting](#-troubleshooting)
- [License](#-license)

---

## ğŸ¯ Overview

This project implements a **production-grade MLOps pipeline** for binary image classification (cat vs. not-cat). The primary goal is **not model accuracy**, but rather to showcase:

âœ… **Automated ML pipelines** with experiment tracking  
âœ… **Orchestrated workflows** with Apache Airflow  
âœ… **Model registry and versioning** with MLflow  
âœ… **Real-time model serving** via REST API  
âœ… **User feedback collection** for continuous improvement  
âœ… **Automated retraining triggers** based on performance metrics  
âœ… **Comprehensive monitoring** with Prometheus & Grafana

**This project is designed for learning and portfolio demonstration of MLOps engineering skills.**

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        USER INTERFACE                           â”‚
â”‚                    Streamlit Web App                            â”‚
â”‚              (Upload Image â†’ Get Prediction)                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      MODEL SERVING                              â”‚
â”‚                  MLflow Model Server                            â”‚
â”‚              (REST API â†’ Production Model)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   EXPERIMENT TRACKING                           â”‚
â”‚                       MLflow                                    â”‚
â”‚        (Track Experiments, Register Models, Artifacts)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PIPELINE ORCHESTRATION                         â”‚
â”‚                    Apache Airflow                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ Training DAG â”‚  â”‚ Deploy DAG   â”‚  â”‚ Monitor DAG  â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               MONITORING & OBSERVABILITY                        â”‚
â”‚              Prometheus + Grafana                               â”‚
â”‚     (Metrics, Dashboards, Alerts, Drift Detection)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **Training Pipeline** (Airflow DAG):

   - Load and preprocess data
   - Train CNN model
   - Log experiments to MLflow
   - Evaluate model performance
   - Promote to production if metrics pass threshold

2. **Deployment Pipeline** (Airflow DAG):

   - Serve production model via MLflow
   - Expose REST API endpoint

3. **User Interaction** (Streamlit):

   - Upload image
   - Get prediction from model server
   - Provide feedback (correct/incorrect)

4. **Monitoring Pipeline** (Airflow DAG):
   - Check model performance metrics
   - Analyze user feedback
   - Trigger retraining if performance degrades
   - Monitor data drift

---

## âœ¨ Features

### Core MLOps Capabilities

- **ğŸ”„ Automated Training Pipeline**

  - Scheduled model retraining
  - Hyperparameter tracking
  - Experiment versioning

- **ğŸ“Š Experiment Tracking**

  - MLflow integration
  - Metric logging (accuracy, precision, recall, F1)
  - Artifact storage (models, plots, datasets)

- **ğŸš€ Model Registry & Versioning**

  - Staged deployments (Staging â†’ Production)
  - Model lineage tracking
  - A/B testing support

- **ğŸŒ Model Serving**

  - REST API for predictions
  - Scalable inference service
  - Low-latency responses

- **ğŸ’¬ Feedback Loop**

  - User feedback collection
  - Ground truth labeling
  - Feedback-driven retraining

- **ğŸ“ˆ Monitoring & Alerting**

  - Real-time performance tracking
  - Data drift detection
  - Automated retraining triggers
  - Custom Grafana dashboards

- **ğŸ³ Containerization**
  - Docker-based deployment
  - Docker Compose orchestration
  - Easy reproducibility

---

## ğŸ› ï¸ Technology Stack

| Layer                   | Technology              | Purpose                            |
| ----------------------- | ----------------------- | ---------------------------------- |
| **ML Framework**        | TensorFlow/Keras        | CNN model development              |
| **Experiment Tracking** | MLflow                  | Track experiments, register models |
| **Orchestration**       | Apache Airflow          | Automate workflows, scheduling     |
| **Model Serving**       | MLflow Serve            | REST API for predictions           |
| **UI**                  | Streamlit               | User interface for predictions     |
| **Monitoring**          | Prometheus              | Metrics collection                 |
| **Visualization**       | Grafana                 | Dashboards and alerts              |
| **Drift Detection**     | DeepChecks/Evidently    | Data quality monitoring            |
| **Containerization**    | Docker + Docker Compose | Service orchestration              |
| **Database**            | PostgreSQL              | Airflow metadata                   |
| **Storage**             | Local/S3                | Artifact storage                   |

---

## ğŸ“ Project Structure

```
are-you-a-cat-mlops-pipeline/
â”‚
â”œâ”€â”€ dags/                          # Airflow DAGs
â”‚   â”œâ”€â”€ train_pipeline.py         # Training orchestration
â”‚   â”œâ”€â”€ deploy_pipeline.py        # Deployment automation
â”‚   â””â”€â”€ monitor_pipeline.py       # Monitoring and retraining triggers
â”‚
â”œâ”€â”€ src/                           # Core ML code
â”‚   â”œâ”€â”€ data_loader.py            # Dataset loading utilities
â”‚   â”œâ”€â”€ preprocess.py             # Image preprocessing
â”‚   â”œâ”€â”€ model_train.py            # Model training logic
â”‚   â”œâ”€â”€ evaluate.py               # Model evaluation
â”‚   â””â”€â”€ inference.py              # Prediction logic
â”‚
â”œâ”€â”€ app/                           # Streamlit application
â”‚   â””â”€â”€ streamlit_app.py          # User interface
â”‚
â”œâ”€â”€ notebooks/                     # Jupyter notebooks
â”‚   â””â”€â”€ exploratory_analysis.ipynb
â”‚
â”œâ”€â”€ data/                          # Data storage
â”‚   â”œâ”€â”€ raw/                      # Raw dataset
â”‚   â”œâ”€â”€ processed/                # Preprocessed data
â”‚   â””â”€â”€ feedback/                 # User feedback logs
â”‚
â”œâ”€â”€ models/                        # Saved models (if not using MLflow)
â”‚
â”œâ”€â”€ mlruns/                        # MLflow tracking data
â”‚
â”œâ”€â”€ config/                        # Configuration files
â”‚   â”œâ”€â”€ prometheus.yml            # Prometheus config
â”‚   â””â”€â”€ grafana/                  # Grafana dashboards
â”‚
â”œâ”€â”€ tests/                         # Unit and integration tests
â”‚   â”œâ”€â”€ test_preprocessing.py
â”‚   â”œâ”€â”€ test_model.py
â”‚   â””â”€â”€ test_api.py
â”‚
â”œâ”€â”€ docker-compose.yml             # Multi-service orchestration
â”œâ”€â”€ Dockerfile                     # Container definition
â”œâ”€â”€ requirements.txt               # Python dependencies
â”œâ”€â”€ .gitignore                    # Git ignore rules
â”œâ”€â”€ .dockerignore                 # Docker ignore rules
â”œâ”€â”€ README.md                      # Project documentation
â””â”€â”€ LICENSE                        # MIT License
```

---

## ğŸ”§ Prerequisites

Before you begin, ensure you have the following installed:

- **Docker** (>= 20.10)
- **Docker Compose** (>= 2.0)
- **Python** (>= 3.10) - for local development
- **Git**
- At least **8GB RAM** available for Docker
- **10GB disk space** for images and artifacts

---

## ğŸš€ Quick Start

### 1. Clone the Repository

```bash
git clone https://github.com/bigalex95/are-you-a-cat-mlops-pipeline.git
cd are-you-a-cat-mlops-pipeline
```

### 2. Start All Services

```bash
docker-compose up -d
```

This will start:

- **MLflow Server** on `http://localhost:5000`
- **Airflow Webserver** on `http://localhost:8080`
- **Streamlit App** on `http://localhost:8501`
- **Prometheus** on `http://localhost:9090`
- **Grafana** on `http://localhost:3000`

### 3. Access the Services

| Service       | URL                   | Default Credentials |
| ------------- | --------------------- | ------------------- |
| MLflow UI     | http://localhost:5000 | No auth             |
| Airflow UI    | http://localhost:8080 | admin / admin       |
| Streamlit App | http://localhost:8501 | No auth             |
| Grafana       | http://localhost:3000 | admin / admin       |
| Prometheus    | http://localhost:9090 | No auth             |

### 4. Trigger Training Pipeline

1. Open Airflow UI at `http://localhost:8080`
2. Enable the `train_pipeline` DAG
3. Click "Trigger DAG" to start training
4. Monitor progress in the DAG graph view

### 5. Make Predictions

1. Open Streamlit app at `http://localhost:8501`
2. Upload a cat or non-cat image
3. View prediction results
4. Provide feedback (correct/incorrect)

---

## ğŸ“– Usage Guide

### Training a Model

#### Option 1: Via Airflow (Automated)

```bash
# Trigger training DAG via CLI
docker exec -it airflow-webserver airflow dags trigger train_pipeline
```

#### Option 2: Local Training (Development)

```bash
# Install dependencies
pip install -r requirements.txt

# Run training script
python src/model_train.py
```

### Viewing Experiments

Navigate to MLflow UI and explore:

- **Experiments**: Compare runs with different hyperparameters
- **Models**: View registered models and their versions
- **Artifacts**: Download trained models, plots, datasets

### Deploying a Model

The deployment DAG automatically serves the latest production model:

```bash
# Check model serving status
curl http://localhost:5001/ping

# Make prediction via API
curl -X POST http://localhost:5001/invocations \
  -H 'Content-Type: application/json' \
  -d '{"instances": [<image_data>]}'
```

### Monitoring

Access Grafana dashboards to view:

- Model accuracy over time
- Prediction latency
- Request rate and error rate
- Data drift metrics
- Feedback statistics

---

## ğŸ“Š Monitoring & Observability

### Key Metrics Tracked

1. **Model Performance**

   - Accuracy, Precision, Recall, F1-score
   - Confusion matrix
   - ROC-AUC curve

2. **Service Health**

   - API response time
   - Request rate (predictions/sec)
   - Error rate
   - CPU/Memory usage

3. **Data Quality**

   - Input distribution shifts
   - Feature drift
   - Label distribution

4. **Business Metrics**
   - Feedback rate
   - User satisfaction
   - Prediction confidence distribution

### Automated Retraining

The monitoring DAG checks performance daily and triggers retraining if:

- Accuracy drops below threshold (e.g., 75%)
- Data drift is detected
- Sufficient new feedback data is collected

---

## ğŸ“ MLOps Maturity Level

This project demonstrates **Level 3 MLOps Maturity**:

| Level       | Description                     | This Project                      |
| ----------- | ------------------------------- | --------------------------------- |
| **Level 0** | Manual process                  | âŒ                                |
| **Level 1** | ML pipeline automation          | âœ… Airflow DAGs                   |
| **Level 2** | CI/CD for ML                    | âœ… Automated deployment           |
| **Level 3** | Automated training + monitoring | âœ… Feedback loop, drift detection |
| **Level 4** | Full MLOps                      | ğŸ”„ In progress                    |

### Level 3 Features Implemented

âœ… Automated training pipelines  
âœ… Experiment tracking and versioning  
âœ… Model registry with staging  
âœ… Automated deployment  
âœ… Model monitoring  
âœ… Data validation  
âœ… Feedback loop  
âœ… Drift detection  
âœ… Automated retraining triggers

---

## ğŸ¯ Learning Objectives

By building and exploring this project, you will learn:

### 1. MLOps Fundamentals

- End-to-end ML pipeline design
- Separation of concerns (data, training, serving, monitoring)
- Reproducibility with containers

### 2. Experiment Tracking

- Logging hyperparameters and metrics
- Comparing model runs
- Artifact management

### 3. Orchestration

- Building Airflow DAGs
- Task dependencies and XComs
- Scheduling and triggers

### 4. Model Serving

- REST API design for ML models
- Model versioning and rollback
- Scalable inference

### 5. Monitoring

- Metrics collection and visualization
- Alerting on performance degradation
- Data drift detection

### 6. DevOps for ML

- Docker containerization
- Multi-service orchestration
- Configuration management

---

## ğŸ—ºï¸ Development Roadmap

### âœ… Phase 1: Foundation

- [x] Project structure setup
- [x] Docker environment
- [x] Basic documentation

### ğŸš§ Phase 2: Core Pipeline (In Progress)

- [ ] Data loading and preprocessing
- [ ] CNN model training
- [ ] MLflow integration

### ğŸ“… Phase 3: Automation

- [ ] Airflow training DAG
- [ ] Airflow deployment DAG
- [ ] Model registry integration

### ğŸ“… Phase 4: User Interface

- [ ] Streamlit app development
- [ ] Feedback collection
- [ ] API integration

### ğŸ“… Phase 5: Monitoring

- [ ] Prometheus metrics
- [ ] Grafana dashboards
- [ ] Drift detection

### ğŸ“… Phase 6: Advanced Features

- [ ] A/B testing support
- [ ] Multi-model comparison
- [ ] Advanced drift detection
- [ ] CI/CD with GitHub Actions

### ğŸ“… Phase 7: Production Readiness

- [ ] Kubernetes deployment
- [ ] Cloud integration (AWS/GCP/Azure)
- [ ] Security hardening
- [ ] Load testing

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these guidelines:

### How to Contribute

1. **Fork the repository**
2. **Create a feature branch**
   ```bash
   git checkout -b feature/amazing-feature
   ```
3. **Make your changes**
4. **Add tests** (if applicable)
5. **Commit your changes**
   ```bash
   git commit -m 'Add amazing feature'
   ```
6. **Push to the branch**
   ```bash
   git push origin feature/amazing-feature
   ```
7. **Open a Pull Request**

### Code Style

- Follow PEP 8 for Python code
- Add docstrings to all functions
- Include type hints
- Write unit tests for new features

### Areas for Contribution

- ğŸ› Bug fixes
- âœ¨ New features (see Roadmap)
- ğŸ“ Documentation improvements
- ğŸ§ª Additional tests
- ğŸ¨ UI/UX enhancements

---

## ğŸ› Troubleshooting

### Common Issues

#### 1. Docker Containers Won't Start

```bash
# Check Docker daemon is running
docker info

# Check logs
docker-compose logs <service-name>

# Rebuild containers
docker-compose down -v
docker-compose up --build
```

#### 2. Airflow Webserver Not Accessible

```bash
# Check Airflow initialization
docker exec -it airflow-webserver airflow db check

# Reinitialize database
docker exec -it airflow-webserver airflow db init
```

#### 3. MLflow Tracking Not Working

```bash
# Check MLflow server logs
docker-compose logs mlflow-server

# Verify tracking URI
echo $MLFLOW_TRACKING_URI
```

#### 4. Out of Memory Errors

```bash
# Increase Docker memory limit in Docker Desktop settings
# Recommended: At least 8GB RAM for Docker
```

### Getting Help

- ğŸ“– Check the [Issues](https://github.com/bigalex95/are-you-a-cat-mlops-pipeline/issues) page
- ğŸ’¬ Open a new issue with detailed error logs
- ğŸ“§ Contact: [Your Email]

---

## ğŸ“š Resources & References

### Official Documentation

- [MLflow Documentation](https://mlflow.org/docs/latest/)
- [Apache Airflow Documentation](https://airflow.apache.org/docs/)
- [TensorFlow Documentation](https://www.tensorflow.org/tutorials)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Docker Documentation](https://docs.docker.com/)

### Learning Materials

- [Made With ML - MLOps](https://madewithml.com/)
- [Full Stack Deep Learning](https://fullstackdeeplearning.com/)
- [MLOps Zoomcamp](https://github.com/DataTalksClub/mlops-zoomcamp)

### Datasets

- [Cats vs Dogs Dataset](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs)

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- TensorFlow team for the excellent ML framework
- MLflow community for experiment tracking tools
- Apache Airflow for workflow orchestration
- Streamlit for easy UI development

---

## ğŸ“ Contact

**Alibek Erkabayev** - [@bigalex95](https://github.com/bigalex95)

Project Link: [https://github.com/bigalex95/are-you-a-cat-mlops-pipeline](https://github.com/bigalex95/are-you-a-cat-mlops-pipeline)

---

## â­ Star History

If you find this project helpful, please consider giving it a star! â­

---

<div align="center">

**Built with â¤ï¸ for learning and demonstrating MLOps best practices**

</div>
