{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6780d3f",
   "metadata": {},
   "source": [
    "# Cats vs Dogs Model Training - Google Colab\n",
    "\n",
    "This notebook allows you to train the Cats vs Dogs classification model on Google Colab with GPU support and save the results using DVC.\n",
    "\n",
    "## Prerequisites\n",
    "- Google account\n",
    "- Access to your GitHub repository\n",
    "- DVC remote credentials (Backblaze B2 or S3)\n",
    "\n",
    "## Steps:\n",
    "1. Setup Colab environment and GPU\n",
    "2. Clone your repository\n",
    "3. Install dependencies\n",
    "4. Configure DVC\n",
    "5. Pull data from DVC\n",
    "6. Train the model\n",
    "7. Save model with DVC\n",
    "8. Push to DVC remote and GitHub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978716ca",
   "metadata": {},
   "source": [
    "## 1. Check GPU Availability\n",
    "\n",
    "Make sure you've enabled GPU in Colab:\n",
    "- Go to Runtime > Change runtime type\n",
    "- Select GPU (T4, A100, or V100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d95959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU available:\", tf.config.list_physical_devices('GPU'))\n",
    "print(\"CUDA available:\", tf.test.is_built_with_cuda())\n",
    "\n",
    "if len(tf.config.list_physical_devices('GPU')) > 0:\n",
    "    print(\"\\n✅ GPU is available! Training will be much faster.\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No GPU detected. Please enable GPU in Runtime > Change runtime type\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa33d5d2",
   "metadata": {},
   "source": [
    "## 2. Clone Your Repository\n",
    "\n",
    "Clone your GitHub repository to access the training code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45330585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "import os\n",
    "\n",
    "# Set your GitHub username and repo name\n",
    "GITHUB_USERNAME = \"bigalex95\"  # Change this to your username\n",
    "REPO_NAME = \"are-you-a-cat-mlops-pipeline\"\n",
    "REPO_URL = f\"https://github.com/{GITHUB_USERNAME}/{REPO_NAME}.git\"\n",
    "\n",
    "# Remove if already exists\n",
    "if os.path.exists(REPO_NAME):\n",
    "    !rm -rf {REPO_NAME}\n",
    "\n",
    "# Clone the repository\n",
    "!git clone {REPO_URL}\n",
    "\n",
    "# Change to repository directory\n",
    "%cd {REPO_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b854a403",
   "metadata": {},
   "source": [
    "## 3. Install Dependencies\n",
    "\n",
    "Install all required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b88d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q tensorflow tensorflow-datasets\n",
    "!pip install -q dvc boto3 s3fs\n",
    "!pip install -q numpy pillow matplotlib seaborn scikit-learn\n",
    "\n",
    "print(\"\\n✅ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b495a027",
   "metadata": {},
   "source": [
    "## 4. Configure DVC Remote\n",
    "\n",
    "Set up your DVC remote credentials. You'll need your Backblaze B2 (or S3) credentials.\n",
    "\n",
    "**Security Note:** Use Colab secrets for sensitive data or enter credentials here (they won't be saved in the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fef580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "\n",
    "# Option 1: Use Colab secrets (recommended)\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    AWS_ACCESS_KEY_ID = userdata.get('AWS_ACCESS_KEY_ID')\n",
    "    AWS_SECRET_ACCESS_KEY = userdata.get('AWS_SECRET_ACCESS_KEY')\n",
    "    print(\"✅ Using credentials from Colab secrets\")\n",
    "except:\n",
    "    # Option 2: Enter credentials manually\n",
    "    print(\"Enter your DVC remote credentials (Backblaze B2 or S3):\")\n",
    "    AWS_ACCESS_KEY_ID = getpass(\"Access Key ID: \")\n",
    "    AWS_SECRET_ACCESS_KEY = getpass(\"Secret Access Key: \")\n",
    "\n",
    "# Set environment variables for DVC\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = AWS_ACCESS_KEY_ID\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = AWS_SECRET_ACCESS_KEY\n",
    "\n",
    "print(\"\\n✅ DVC credentials configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c634071",
   "metadata": {},
   "source": [
    "## 5. Pull Data from DVC\n",
    "\n",
    "Download the processed training data from your DVC remote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2182dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DVC and pull data\n",
    "!dvc pull data/processed.dvc\n",
    "\n",
    "# Verify data is downloaded\n",
    "!ls -lh data/processed/\n",
    "\n",
    "print(\"\\n✅ Training data downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec423348",
   "metadata": {},
   "source": [
    "## 6. Load and Verify Data\n",
    "\n",
    "Load the preprocessed data and check its shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6126972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "# Add src to Python path\n",
    "sys.path.append('src')\n",
    "\n",
    "# Load processed data\n",
    "print(\"Loading processed data...\")\n",
    "X_train = np.load('data/processed/train_images.npy')\n",
    "y_train = np.load('data/processed/train_labels.npy')\n",
    "X_val = np.load('data/processed/val_images.npy')\n",
    "y_val = np.load('data/processed/val_labels.npy')\n",
    "X_test = np.load('data/processed/test_images.npy')\n",
    "y_test = np.load('data/processed/test_labels.npy')\n",
    "\n",
    "print(f\"\\nData shapes:\")\n",
    "print(f\"  Training:   {X_train.shape} images, {y_train.shape} labels\")\n",
    "print(f\"  Validation: {X_val.shape} images, {y_val.shape} labels\")\n",
    "print(f\"  Test:       {X_test.shape} images, {y_test.shape} labels\")\n",
    "\n",
    "print(f\"\\nClass distribution:\")\n",
    "print(f\"  Training:   {np.sum(y_train == 0)} cats, {np.sum(y_train == 1)} dogs\")\n",
    "print(f\"  Validation: {np.sum(y_val == 0)} cats, {np.sum(y_val == 1)} dogs\")\n",
    "print(f\"  Test:       {np.sum(y_test == 0)} cats, {np.sum(y_test == 1)} dogs\")\n",
    "\n",
    "print(\"\\n✅ Data loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e4d0e1",
   "metadata": {},
   "source": [
    "## 7. Visualize Sample Images\n",
    "\n",
    "Let's look at some sample images to verify the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize some training images\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in range(10):\n",
    "    axes[i].imshow(X_train[i])\n",
    "    label = \"Dog\" if y_train[i] == 1 else \"Cat\"\n",
    "    axes[i].set_title(f\"{label}\")\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Sample images displayed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb65572",
   "metadata": {},
   "source": [
    "## 8. Build and Compile Model\n",
    "\n",
    "Create the CNN model for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3e9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_train import build_cnn_model, compile_model\n",
    "\n",
    "# Build the model\n",
    "print(\"Building model...\")\n",
    "model = build_cnn_model(\n",
    "    input_shape=(150, 150, 3),\n",
    "    num_classes=1\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "print(\"\\nCompiling model...\")\n",
    "model = compile_model(\n",
    "    model,\n",
    "    learning_rate=0.001,\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy'\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Model built and compiled!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff0a51a",
   "metadata": {},
   "source": [
    "## 9. Set Up Training Callbacks\n",
    "\n",
    "Configure callbacks for better training (early stopping, model checkpointing, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c3d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_train import create_callbacks\n",
    "\n",
    "# Create callbacks\n",
    "callbacks = create_callbacks(\n",
    "    model_save_path='models/best_model_colab.keras',\n",
    "    monitor='val_loss',\n",
    "    patience=5\n",
    ")\n",
    "\n",
    "print(\"✅ Training callbacks configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c77ca6",
   "metadata": {},
   "source": [
    "## 10. Train the Model\n",
    "\n",
    "Now let's train the model! This may take 15-30 minutes depending on your GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb64db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_train import train_model\n",
    "import time\n",
    "\n",
    "# Training configuration\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(f\"Starting training...\")\n",
    "print(f\"  Epochs: {EPOCHS}\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Training samples: {len(X_train)}\")\n",
    "print(f\"  Validation samples: {len(X_val)}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "history = train_model(\n",
    "    model,\n",
    "    train_data=(X_train, y_train),\n",
    "    val_data=(X_val, y_val),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"✅ Training completed in {training_time/60:.2f} minutes!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33139c7",
   "metadata": {},
   "source": [
    "## 11. Visualize Training History\n",
    "\n",
    "Plot the training and validation metrics to see how the model performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89913f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plot accuracy\n",
    "axes[0].plot(history.history['accuracy'], label='Training Accuracy')\n",
    "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "axes[0].set_title('Model Accuracy')\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Plot loss\n",
    "axes[1].plot(history.history['loss'], label='Training Loss')\n",
    "axes[1].plot(history.history['val_loss'], label='Validation Loss')\n",
    "axes[1].set_title('Model Loss')\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Loss')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print final metrics\n",
    "print(\"\\nFinal Training Metrics:\")\n",
    "print(f\"  Training Accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "print(f\"  Validation Accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "print(f\"  Training Loss: {history.history['loss'][-1]:.4f}\")\n",
    "print(f\"  Validation Loss: {history.history['val_loss'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7ddcbc",
   "metadata": {},
   "source": [
    "## 12. Evaluate on Test Set\n",
    "\n",
    "Test the model on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea9cd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"Evaluating model on test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "print(f\"\\n\" + \"=\"*80)\n",
    "print(f\"Test Results:\")\n",
    "print(f\"  Test Accuracy: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47d7070",
   "metadata": {},
   "source": [
    "## 13. Save Final Model\n",
    "\n",
    "Save the trained model in the models directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ad74ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_train import save_model\n",
    "from datetime import datetime\n",
    "\n",
    "# Create models directory\n",
    "!mkdir -p models\n",
    "\n",
    "# Save with timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "model_filename = f\"models/cats_vs_dogs_model_colab_{timestamp}.keras\"\n",
    "\n",
    "# Also save as the main model\n",
    "main_model_path = \"models/cats_vs_dogs_model.keras\"\n",
    "\n",
    "save_model(model, model_filename)\n",
    "save_model(model, main_model_path)\n",
    "\n",
    "print(f\"\\n✅ Model saved to:\")\n",
    "print(f\"  - {model_filename}\")\n",
    "print(f\"  - {main_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448a6144",
   "metadata": {},
   "source": [
    "## 14. Add Model to DVC\n",
    "\n",
    "Track the model with DVC for version control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6ff830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add model to DVC\n",
    "!dvc add models/cats_vs_dogs_model.keras\n",
    "\n",
    "print(\"\\n✅ Model added to DVC!\")\n",
    "\n",
    "# Show what was created\n",
    "!ls -lh models/*.dvc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfd0f88",
   "metadata": {},
   "source": [
    "## 15. Push Model to DVC Remote\n",
    "\n",
    "Upload the model to your DVC remote storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1944d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push model to DVC remote\n",
    "!dvc push models/cats_vs_dogs_model.keras.dvc\n",
    "\n",
    "print(\"\\n✅ Model pushed to DVC remote!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc91bbec",
   "metadata": {},
   "source": [
    "## 16. Commit and Push to GitHub\n",
    "\n",
    "Save the DVC metadata files to GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2065ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure git (replace with your info)\n",
    "!git config --global user.email \"your.email@example.com\"\n",
    "!git config --global user.name \"Your Name\"\n",
    "\n",
    "# Add DVC files\n",
    "!git add models/cats_vs_dogs_model.keras.dvc models/.gitignore\n",
    "\n",
    "# Commit changes\n",
    "!git commit -m \"Add trained model from Colab - Test Accuracy: {test_accuracy:.4f}\"\n",
    "\n",
    "print(\"\\n✅ Changes committed!\")\n",
    "print(\"\\nTo push to GitHub, you'll need to authenticate.\")\n",
    "print(\"Run the following command manually:\")\n",
    "print(\"  git push origin model-development\")\n",
    "print(\"\\nOr authenticate with a personal access token.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e986c7",
   "metadata": {},
   "source": [
    "## 17. Download Model (Optional)\n",
    "\n",
    "Download the trained model to your local machine if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a97681c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download the model file\n",
    "print(\"Downloading model...\")\n",
    "files.download(main_model_path)\n",
    "\n",
    "print(\"\\n✅ Model downloaded to your local machine!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7014c9ed",
   "metadata": {},
   "source": [
    "## 18. Summary and Next Steps\n",
    "\n",
    "### What we accomplished:\n",
    "1. ✅ Set up Google Colab with GPU\n",
    "2. ✅ Cloned your repository\n",
    "3. ✅ Installed dependencies\n",
    "4. ✅ Configured DVC remote\n",
    "5. ✅ Pulled training data from DVC\n",
    "6. ✅ Trained the CNN model\n",
    "7. ✅ Evaluated on test set\n",
    "8. ✅ Saved model with DVC\n",
    "9. ✅ Pushed model to DVC remote\n",
    "\n",
    "### Next Steps:\n",
    "1. Push the changes to GitHub (you may need to do this locally with credentials)\n",
    "2. Pull the model on your local machine: `dvc pull models/cats_vs_dogs_model.keras.dvc`\n",
    "3. Test the model with your inference pipeline\n",
    "4. Deploy the model using your Streamlit app\n",
    "\n",
    "### Tips:\n",
    "- Save this notebook to your Google Drive for future training sessions\n",
    "- You can experiment with different hyperparameters (learning rate, batch size, etc.)\n",
    "- Try data augmentation for better performance\n",
    "- Monitor training in real-time with the progress bars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3307778",
   "metadata": {},
   "source": [
    "## Optional: Test Model Predictions\n",
    "\n",
    "Test the model on some sample images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2846d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Test on random samples\n",
    "num_samples = 10\n",
    "random_indices = np.random.choice(len(X_test), num_samples, replace=False)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, idx in enumerate(random_indices):\n",
    "    # Get image and true label\n",
    "    image = X_test[idx]\n",
    "    true_label = \"Dog\" if y_test[idx] == 1 else \"Cat\"\n",
    "    \n",
    "    # Make prediction\n",
    "    prediction = model.predict(np.expand_dims(image, axis=0), verbose=0)[0][0]\n",
    "    predicted_label = \"Dog\" if prediction > 0.5 else \"Cat\"\n",
    "    confidence = prediction if prediction > 0.5 else 1 - prediction\n",
    "    \n",
    "    # Display\n",
    "    axes[i].imshow(image)\n",
    "    color = 'green' if true_label == predicted_label else 'red'\n",
    "    axes[i].set_title(f\"True: {true_label}\\nPred: {predicted_label} ({confidence:.2%})\", color=color)\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Green = Correct prediction, Red = Incorrect prediction\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
